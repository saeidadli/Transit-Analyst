{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-9d54f10964b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshapely\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometry\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgeom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mDIR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDIR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import time \n",
    "import shutil\n",
    "import math\n",
    "import sys\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gtfstk as gt\n",
    "\n",
    "import geopandas as gp\n",
    "import shapely.geometry as geom\n",
    "\n",
    "DIR = Path('..')\n",
    "sys.path.append(str(DIR))\n",
    "\n",
    "DATA_DIR = DIR/'data/'\n",
    "\n",
    "import gtfsanalyst as hp\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_feed_segments(feed):\n",
    "    feed,\n",
    "    max_cuf_off = 2 * 3600, \n",
    "    analysis_start = 10800,\n",
    "    analysis_end = 97140, \n",
    "    convert_to_gpd = False): \n",
    "    \"\"\"\n",
    "    The objective is to create a dataframe of all links in a GTFS\n",
    "    a link connects two stops and includes these fields:\n",
    "        - origin stop (o_stop), in other words this is start node of a link\n",
    "        - origin stop (o_stop) xy\n",
    "        - origin time (o_time), in other words this is start time of link\n",
    "        - destination stop (d_stop), in other words this is end of link\n",
    "        - destination time (d_time), in other words this is end time of link\n",
    "        - origin stop (d_stop) xy\n",
    "        - trip id (trip_id), in other words this is the name of the trip that connects the nodes of this link.\n",
    "        - route id (route_id), in other words this is the name of the route that connects the nodes of this link.\n",
    "        - transit mode (type), in other words this could be for example bus, ferry, rail, etc.\n",
    "        - the travel time (duration), in other words how long it take to go from one node to another.\n",
    "        - the sequence of stops after the link, this will help to find averate wait time and remove duplice services\n",
    "    Notes:\n",
    "        - tne input must be a dictionary of GTFS tables in pandas dataframe format\n",
    "        - the keys in this dictinonary must be GTFS table names\n",
    "        - max cut off is the maximum travel time in seconds. The default is 2 hours.\n",
    "        - analysis period is a list of two times the default is '03:00:00' to '26:59:00'\n",
    "    \"\"\"\n",
    "    \n",
    "    analysis_duration_sec = (analysis_end - analysis_start) \n",
    "    analysis_duration_h = analysis_duration_sec / 3600\n",
    "    analysis_mid_sec = analysis_start + (analysis_duration_sec / 2)\n",
    "    analysis_start_sec = analysis_start\n",
    "    analysis_end_sec = analysis_mid_sec + max_cuf_off + (0.25 * 3600)\n",
    "    \n",
    "\n",
    "    \n",
    "    def fix_dup_tirps(row):\n",
    "        sid = row['o_stop']+\";\"\n",
    "        seq = row['stop_seq']\n",
    "        return seq.split(sid, 1)[-1]\n",
    "\n",
    "    if not PT_links_df.empty:\n",
    "        PT_links_df['stop_seq'] = PT_links_df.apply(fix_dup_tirps, axis = 1)\n",
    "        \n",
    "        PT_links_df = PT_links_df.merge(feed['stops'][['stop_id', 'stop_lat', 'stop_lon']], \n",
    "                                        left_on='o_stop', \n",
    "                                        right_on='stop_id', \n",
    "                                        how='left').drop('stop_id', axis = 1) \n",
    "        PT_links_df.rename(columns = {'stop_lat': 'o_stop_lat',\n",
    "                                      'stop_lon': 'o_stop_lon'},\n",
    "                          inplace = True)\n",
    "        PT_links_df = PT_links_df.merge(feed['stops'][['stop_id', 'stop_lat', 'stop_lon']], \n",
    "                                        left_on='d_stop', \n",
    "                                        right_on='stop_id', \n",
    "                                        how='left').drop('stop_id', axis = 1)\n",
    "        PT_links_df.rename(columns = {'stop_lat': 'd_stop_lat',\n",
    "                                      'stop_lon': 'd_stop_lon'},\n",
    "                          inplace = True)\n",
    "    \n",
    "    #calculates the average wait time (awt) depending on the analysis awt period.\n",
    " \n",
    "    #removes the PT links outside the analysis awt period\n",
    "    cond = (PT_links_df['o_time_sec'] >= analysis_start)&\\\n",
    "           (PT_links_df['d_time_sec'] <= analysis_end)\n",
    "\n",
    "    #calculates the frequency of trips\n",
    "    frq_df = PT_links_df[cond]['stop_seq'].value_counts().reset_index()\n",
    "    frq_df.columns = ['stop_seq', 'freq']\n",
    "    frq_df['freq'] = frq_df['freq'] / analysis_duration_h # frequency per hour\n",
    "\n",
    "    # keep only three hours period for simplicity\n",
    "    cond = (PT_links_df['o_time_sec'] >= analysis_mid_sec)&\\\n",
    "           (PT_links_df['d_time_sec'] <= analysis_end_sec)\n",
    "    PT_links_df = PT_links_df[cond].copy().merge(frq_df, how = 'left')\n",
    "    #calculates the awt\n",
    "    PT_links_df['awt'] = 3600 / PT_links_df['freq'] / 2 #average waite time (sec) is half the headway\n",
    "    \n",
    "    PT_links_df.fillna(0, inplace=True)\n",
    "    \n",
    "    if convert_to_gpd == True:\n",
    "        #converting the PT_links_df to a geodataframe\n",
    "        l = lambda x: geom.LineString([geom.Point(x.o_stop_lon,x.o_stop_lat), geom.Point(x.d_stop_lon, x.d_stop_lat)])\n",
    "        PT_links_df['geometry'] = PT_links_df.apply(l, axis=1)\n",
    "        PT_links_gdf = gp.GeoDataFrame(PT_links_df)\n",
    "        return PT_links_gdf\n",
    "\n",
    "    return PT_links_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4febad376ce9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mFeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFeed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     def __init__(self, dist_units, agency=None, stops=None, routes=None,\n\u001b[0;32m      3\u001b[0m         \u001b[0mtrips\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcalendar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcalendar_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mfare_attributes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfare_rules\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         frequencies=None, transfers=None, feed_info=None, feed_segments=None):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gt' is not defined"
     ]
    }
   ],
   "source": [
    "class Feed(gt.Feed):\n",
    "    def __init__(self, dist_units, agency=None, stops=None, routes=None,\n",
    "        trips=None, stop_times=None, calendar=None, calendar_dates=None,\n",
    "        fare_attributes=None, fare_rules=None, shapes=None,\n",
    "        frequencies=None, transfers=None, feed_info=None, feed_segments=None):\n",
    "        \n",
    "        gt.Feed.__init__(self, dist_units, agency=None, stops=None, routes=None,\n",
    "            trips=None, stop_times=None, calendar=None, calendar_dates=None,\n",
    "            fare_attributes=None, fare_rules=None, shapes=None,\n",
    "            frequencies=None, transfers=None, feed_info=None)\n",
    "        \n",
    "        self.feed_segments = feed_segs   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gtfs(path, dist_units=None):\n",
    "    \"\"\"\n",
    "    Create a Feed instance from the given path and given distance units.\n",
    "    The path should be a directory containing GTFS text files or a\n",
    "    zip file that unzips as a collection of GTFS text files\n",
    "    (and not as a directory containing GTFS text files).\n",
    "    The distance units given must lie in :const:`constants.dist_units`\n",
    "    Notes\n",
    "    -----\n",
    "    - Ignore non-GTFS files\n",
    "    - Automatically strip whitespace from the column names in GTFS files\n",
    "    - This is based on gtfstk library\n",
    "    \"\"\"\n",
    "    gt_feed = gt.read_gtfs(path, dist_units)\n",
    "    \n",
    "    #calculate segments\n",
    "    feed_dict = hp.feed_obj_to_dict(feed_obj) \n",
    "    \n",
    "    PT_links_df =  feed_dict['stop_times'].copy()\n",
    "    PT_links_df.rename(columns = {'arrival_time': 'o_time', \n",
    "                                  'stop_id': 'o_stop',\n",
    "                                  'stop_sequence': 'o_sequence'}, inplace = True)  \n",
    "    \n",
    "    PT_links_df[['d_time', 'd_stop', 'd_sequence']] = PT_links_df[['o_time', 'o_stop', 'o_sequence']].shift(-1)\n",
    "    \n",
    "    PT_links_df = PT_links_df[PT_links_df['o_sequence'] < PT_links_df['d_sequence']].copy() #removes the last stops\n",
    "    \n",
    "    #Convert the time into seconds for easier time calculatins\n",
    "    PT_links_df['o_time_sec'] = PT_links_df['o_time'].apply(hp.text2sec)\n",
    "    PT_links_df['d_time_sec'] = PT_links_df['d_time'].apply(hp.text2sec)\n",
    "    PT_links_df['duration'] = PT_links_df['d_time_sec'] - PT_links_df['o_time_sec']\n",
    "    \n",
    "    #Add route_id using the trips table\n",
    "    PT_links_df = PT_links_df.merge(feed['trips'])\n",
    "        \n",
    "    #Add route type in text format to the link dataset\n",
    "    PT_links_df = PT_links_df.merge(feed['routes'])\n",
    "\n",
    "    route_type = {'0': 'Tram, Streetcar, Light rail',\n",
    "                  '1': 'Subway, Metro',\n",
    "                  '2': 'Rail',\n",
    "                  '3': 'Bus',\n",
    "                  '4': 'Ferry',\n",
    "                  '5': 'Cable car',\n",
    "                  '6': 'Gondola, Suspended cable car',\n",
    "                  '7': 'Funicular'}\n",
    "\n",
    "    PT_links_df['route_type'] = PT_links_df['route_type'].astype(str)\n",
    "    PT_links_df['route_type'].replace(route_type, inplace = True)\n",
    "\n",
    "    #add stop sequence to PT_links_df\n",
    "    stop_seq_df = stop_seq_for_trips(feed['stop_times'])\n",
    "    PT_links_df = PT_links_df.merge(stop_seq_df)\n",
    "    \n",
    "    feed_dict['feed_segments'] = PT_links_df\n",
    "    \n",
    "    return Feed(**feed_dict)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
